{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset folder:\n",
      "['0.circles', '0.edges', '0.egofeat', '0.feat', '0.featnames', '107.circles', '107.edges', '107.egofeat', '107.feat', '107.featnames', '1684.circles', '1684.edges', '1684.egofeat', '1684.feat', '1684.featnames', '1912.circles', '1912.edges', '1912.egofeat', '1912.feat', '1912.featnames', '3437.circles', '3437.edges', '3437.egofeat', '3437.feat', '3437.featnames', '348.circles', '348.edges', '348.egofeat', '348.feat', '348.featnames', '3980.circles', '3980.edges', '3980.egofeat', '3980.feat', '3980.featnames', '414.circles', '414.edges', '414.egofeat', '414.feat', '414.featnames', '686.circles', '686.edges', '686.egofeat', '686.feat', '686.featnames', '698.circles', '698.edges', '698.egofeat', '698.feat', '698.featnames']\n",
      "Identified prefixes for networks:\n",
      "{'0', '686', '1684', '107', '3980', '3437', '1912', '698', '414', '348'}\n",
      "Processing network: 0\n",
      "Warning: Number of features does not match number of nodes (348 vs 333)\n",
      "Processing network: 107\n",
      "Warning: Number of features does not match number of nodes (1046 vs 1034)\n",
      "Processing network: 1684\n",
      "Warning: Number of features does not match number of nodes (793 vs 786)\n",
      "Processing network: 1912\n",
      "Warning: Number of features does not match number of nodes (756 vs 747)\n",
      "Processing network: 3437\n",
      "Warning: Number of features does not match number of nodes (548 vs 534)\n",
      "Processing network: 348\n",
      "Warning: Number of features does not match number of nodes (228 vs 224)\n",
      "Processing network: 3980\n",
      "Warning: Number of features does not match number of nodes (60 vs 52)\n",
      "Processing network: 414\n",
      "Warning: Number of features does not match number of nodes (160 vs 150)\n",
      "Processing network: 686\n",
      "Warning: Number of features does not match number of nodes (171 vs 168)\n",
      "Processing network: 698\n",
      "Warning: Number of features does not match number of nodes (67 vs 61)\n",
      "Network 0:\n",
      "  Nodes: 333\n",
      "  Edges: 5038\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load edges from .edges file\n",
    "def load_edges(file_path):\n",
    "    edges = []\n",
    "    nodes = set()  # To track unique nodes\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            u, v = map(int, line.strip().split())\n",
    "            edges.append((u, v))\n",
    "            nodes.add(u)\n",
    "            nodes.add(v)\n",
    "    return edges, list(nodes)\n",
    "\n",
    "# Load features from .feats and .egofeat files\n",
    "def load_features(feat_path, egofeat_path, node_ids):\n",
    "    # Read feature files\n",
    "    features = pd.read_csv(feat_path, delim_whitespace=True, header=None)\n",
    "    ego_features = pd.read_csv(egofeat_path, delim_whitespace=True, header=None)\n",
    "    # Combine the features\n",
    "    features = pd.concat([features, ego_features], ignore_index=True)\n",
    "    \n",
    "    # Check if number of features matches number of nodes\n",
    "    if len(features) != len(node_ids):\n",
    "        print(f\"Warning: Number of features does not match number of nodes ({len(features)} vs {len(node_ids)})\")\n",
    "    \n",
    "    # Create a mapping from node IDs to features\n",
    "    node_feature_map = dict(zip(node_ids, features.values))\n",
    "    return node_feature_map\n",
    "\n",
    "# Build a graph from the dataset files\n",
    "def build_graph(edges, node_feature_map):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Add features as node attributes\n",
    "    for node_id, features in node_feature_map.items():\n",
    "        G.nodes[node_id]['feature'] = features.tolist()\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Process all networks in the dataset folder\n",
    "def process_dataset(dataset_path):\n",
    "    networks = {}\n",
    "    \n",
    "    # Check the dataset folder\n",
    "    print(\"Files in dataset folder:\")\n",
    "    print(os.listdir(dataset_path))\n",
    "    \n",
    "    # Identify unique prefixes (e.g., 0, 1, ...)\n",
    "    prefixes = set()\n",
    "    for file_name in os.listdir(dataset_path):\n",
    "        if file_name.endswith(\".edges\"):\n",
    "            prefix = file_name.split('.')[0]\n",
    "            prefixes.add(prefix)\n",
    "    \n",
    "    print(\"Identified prefixes for networks:\")\n",
    "    print(prefixes)\n",
    "    \n",
    "    # Process each prefix\n",
    "    for prefix in sorted(prefixes):\n",
    "        edges_path = os.path.join(dataset_path, f\"{prefix}.edges\")\n",
    "        feat_path = os.path.join(dataset_path, f\"{prefix}.feat\")\n",
    "        egofeat_path = os.path.join(dataset_path, f\"{prefix}.egofeat\")\n",
    "        \n",
    "        # Check if all required files exist\n",
    "        if os.path.exists(edges_path) and os.path.exists(feat_path) and os.path.exists(egofeat_path):\n",
    "            print(f\"Processing network: {prefix}\")\n",
    "            edges, node_ids = load_edges(edges_path)\n",
    "            node_feature_map = load_features(feat_path, egofeat_path, node_ids)\n",
    "            graph = build_graph(edges, node_feature_map)\n",
    "            networks[prefix] = graph\n",
    "        else:\n",
    "            print(f\"Skipping {prefix}: Missing one or more files\")\n",
    "    \n",
    "    return networks\n",
    "\n",
    "# Path to the dataset folder\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "# Process all networks\n",
    "networks = process_dataset(dataset_path)\n",
    "\n",
    "# Check if any networks were processed\n",
    "if not networks:\n",
    "    print(\"No networks were processed. Please check the dataset structure and paths.\")\n",
    "else:\n",
    "    # Access and analyze one of the networks\n",
    "    example_prefix = list(networks.keys())[0]\n",
    "    example_graph = networks[example_prefix]\n",
    "    print(f\"Network {example_prefix}:\")\n",
    "    print(f\"  Nodes: {example_graph.number_of_nodes()}\")\n",
    "    print(f\"  Edges: {example_graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final infected nodes: []\n",
      "Final active nodes: {0, 1, 2, 69, 62}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Constants for node states\n",
    "UNINFECTED = 0\n",
    "ACTIVE = 1\n",
    "INFECTED = 2\n",
    "\n",
    "# Independent Cascade model for rumor propagation\n",
    "def independent_cascade(G, seed_nodes, activation_prob=0.1):\n",
    "    # Initialize all nodes as Uninfected\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node]['state'] = UNINFECTED\n",
    "    \n",
    "    # Seed nodes become Active\n",
    "    for seed in seed_nodes:\n",
    "        G.nodes[seed]['state'] = ACTIVE\n",
    "    \n",
    "    active_nodes = set(seed_nodes)\n",
    "    newly_active = set(seed_nodes)\n",
    "    \n",
    "    # Simulation loop for rumor propagation\n",
    "    while newly_active:\n",
    "        next_active = set()\n",
    "        for node in newly_active:\n",
    "            # Propagate the rumor to neighbors\n",
    "            for neighbor in G.neighbors(node):\n",
    "                if G.nodes[neighbor]['state'] == UNINFECTED:  # Only uninfected nodes can be infected\n",
    "                    # Propagate with a probability (activation)\n",
    "                    if np.random.rand() < activation_prob:\n",
    "                        next_active.add(neighbor)\n",
    "                        G.nodes[neighbor]['state'] = ACTIVE  # Activate the node\n",
    "        active_nodes.update(next_active)\n",
    "        newly_active = next_active\n",
    "    \n",
    "    # Return the final set of infected nodes\n",
    "    infected_nodes = [node for node, data in G.nodes(data=True) if data['state'] == INFECTED]\n",
    "    return infected_nodes, active_nodes\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "G = nx.erdos_renyi_graph(100, 0.05)  # Example graph, adjust size and density as needed\n",
    "seed_nodes = [0, 1, 2]  # Example seed nodes to start the rumor\n",
    "\n",
    "# Run the IC model\n",
    "infected_nodes, active_nodes = independent_cascade(G, seed_nodes, activation_prob=0.1)\n",
    "print(f\"Final infected nodes: {infected_nodes}\")\n",
    "print(f\"Final active nodes: {active_nodes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_rumor_propagation(G, alpha=0.5):\n",
    "    # Calculate probability of rumor spread using SRPM\n",
    "    for u, v in G.edges:\n",
    "        out_u = G.out_degree(u)  # OUT(u): Number of outgoing edges from u\n",
    "        in_v = G.in_degree(v)    # IN(v): Number of incoming edges to v\n",
    "        p_uv = (alpha * np.log(1 + out_u)) / (alpha * np.log(1 + out_u) + (1 - alpha) * np.log(1 + in_v))\n",
    "        G[u][v]['p'] = p_uv  # Store the probability in the edge attribute\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def dynamic_rumor_propagation(G, alpha_0=0.5, lambda_param=0.5, c1=0.1, c2=0.1, t_max=10):\n",
    "    # Simulate the rumor spread dynamically over multiple time steps\n",
    "    alpha_t = alpha_0\n",
    "    for t in range(t_max):\n",
    "        # Update probabilities at time t\n",
    "        for u, v in G.edges:\n",
    "            out_u = G.out_degree(u)\n",
    "            in_v = G.in_degree(v)\n",
    "            p_uv_t = (alpha_t * np.log(1 + out_u)) / (alpha_t * np.log(1 + out_u) + (1 - alpha_t) * np.log(1 + in_v))\n",
    "            G[u][v]['p'] = p_uv_t\n",
    "        \n",
    "        # Calculate the dynamic popularity alpha_t\n",
    "        A_t = [node for node, data in G.nodes(data=True) if data['state'] == ACTIVE]\n",
    "        I_t = [node for node, data in G.nodes(data=True) if data['state'] == INFECTED]\n",
    "        \n",
    "        alpha_t = (lambda_param * len(A_t) + c1) / (len(I_t) + c2)\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Constants for node states\n",
    "UNINFECTED = 0\n",
    "ACTIVE = 1\n",
    "INFECTED = 2\n",
    "BLOCKED = 3\n",
    "\n",
    "class RumorRL:\n",
    "    def __init__(self, graph, activation_prob=0.1):\n",
    "        self.G = graph\n",
    "        self.activation_prob = activation_prob\n",
    "        self.reset()\n",
    "\n",
    "    # Reset the environment (state) to its initial configuration\n",
    "    def reset(self):\n",
    "        for node in self.G.nodes:\n",
    "            self.G.nodes[node]['state'] = UNINFECTED\n",
    "        self.state = [UNINFECTED] * len(self.G.nodes)\n",
    "        return self.state\n",
    "    \n",
    "    # Simulate rumor spread and return the number of newly infected nodes\n",
    "    def propagate_rumor(self, seed_nodes):\n",
    "        active_nodes = set(seed_nodes)\n",
    "        newly_active = set(seed_nodes)\n",
    "\n",
    "        while newly_active:\n",
    "            next_active = set()\n",
    "            for node in newly_active:\n",
    "                for neighbor in self.G.neighbors(node):\n",
    "                    if self.G.nodes[neighbor]['state'] == UNINFECTED:\n",
    "                        if np.random.rand() < self.activation_prob:\n",
    "                            next_active.add(neighbor)\n",
    "                            self.G.nodes[neighbor]['state'] = ACTIVE\n",
    "            active_nodes.update(next_active)\n",
    "            newly_active = next_active\n",
    "        \n",
    "        # Count the number of infected nodes\n",
    "        infected_nodes = [node for node, data in self.G.nodes(data=True) if data['state'] == INFECTED]\n",
    "        return len(infected_nodes)\n",
    "\n",
    "    # Block a node by setting its state to BLOCKED\n",
    "    def block_node(self, node_id):\n",
    "        self.G.nodes[node_id]['state'] = BLOCKED\n",
    "        self.state[node_id] = BLOCKED\n",
    "\n",
    "    # Take an action (block a node) and return the new state and reward\n",
    "    def step(self, action):\n",
    "        # Block the selected node\n",
    "        self.block_node(action)\n",
    "        \n",
    "        # Run the rumor propagation and calculate the reward\n",
    "        infected_before = self.propagate_rumor([0])  # Example: assume rumor starts from node 0\n",
    "        infected_after = self.propagate_rumor([0])  # After blocking one node\n",
    "        reward = -(infected_after - infected_before)\n",
    "        \n",
    "        # Return the new state and the reward\n",
    "        return self.state, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, env, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01, batch_size=32, memory_size=10000):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        \n",
    "        self.input_dim = len(env.state)  # State dimension\n",
    "        self.output_dim = len(env.G.nodes)  # Action space: Block any node\n",
    "        self.q_network = QNetwork(self.input_dim, self.output_dim)\n",
    "        self.target_network = QNetwork(self.input_dim, self.output_dim)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=0.001)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.choice(range(self.output_dim))  # Random action (exploration)\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = self.q_network(state_tensor)\n",
    "        return torch.argmax(q_values).item()  # Action with max Q-value (exploitation)\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        states, actions, rewards, next_states = zip(*batch)\n",
    "        \n",
    "        states_tensor = torch.FloatTensor(states)\n",
    "        actions_tensor = torch.LongTensor(actions)\n",
    "        rewards_tensor = torch.FloatTensor(rewards)\n",
    "        next_states_tensor = torch.FloatTensor(next_states)\n",
    "        \n",
    "        # Get Q-values from the current network\n",
    "        q_values = self.q_network(states_tensor).gather(1, actions_tensor.unsqueeze(1))\n",
    "        \n",
    "        # Get target Q-values from the target network\n",
    "        next_q_values = self.target_network(next_states_tensor).max(1)[0].detach()\n",
    "        target_q_values = rewards_tensor + self.gamma * next_q_values\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(q_values.squeeze(), target_q_values)\n",
    "        \n",
    "        # Optimize the Q-network\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Update epsilon for exploration-exploitation tradeoff\n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        # Periodically update the target network\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "# Example usage:\n",
    "env = RumorRL(G)  # Assuming G is the graph created earlier\n",
    "agent = DQNAgent(env)\n",
    "\n",
    "# Training loop\n",
    "for episode in range(1000):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state)\n",
    "        agent.learn()\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    print(f\"Episode {episode}: Total Reward = {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
